{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Últimas tentativas e considerações\n",
    "\n",
    "Observamos que escalonar os dados não deu muito certo, manipular os dados e gerar novos atributos também não. Como comentato anteriormente, talvez pela natureza dos dados sintéticos.\n",
    "\n",
    "Olhamos alguns exemplos no kaggle,  reparamos que muitas pessoas passaram pelas menas dificuldades que as nossas, e nisso reparamos na discussão de um algoritmo que o XGBoost. Ele é um Ensemble de Ensemble assim como Voting Classifier. Como o nome já diz é um boosting que assim como o Gradient vai analisando os erros residuais, minimizando as perdas. Diferente do Voting Classifier que é mais generico, mas que pode combinar diferentes modelos de votação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df_after_models.pkl')\n",
    "\n",
    "df_test = pd.read_pickle('df_test_after_models.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
